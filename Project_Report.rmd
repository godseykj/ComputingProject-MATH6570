---
title: "Project_Computation"
author: "Mansi Darji"
date: "12/11/2021"
output: 
  html_document:
    code_folding: show
    theme: journal
    toc: yes
    to _float: yes
  word_document:
    toc: yes
---


## Section-1: Introduction
### Introduction
  
Normal distributions are most common distributions used in statistical theory and applications. Performing statistical analysis using parametric methods, validation of the normality assumption must need to be checked. Graphical methods like histogram, Q-Q plot or box plot can be used to check that assumption. Due to subjective nature of these methods, they do not provide the formal conclusive evidence about normality assumption. Formal normality tests come to handy and can be reliable for validating normality assumption. There are a significant number of tests of normality available. But, they are created under certain conditions or assumptions.This paper did the comparison of 8 selected normality tests based on Type I error rate and power of these tests.

1. Shapiro-Wilk test(SW test)
2. Kolmogorov-Smirnov test(KS test)
3. Lilliefors test(LL test)
4. Cramer-Von mises test (CVM test)
5. Pearson's Chi-Squared test (CSQ test)
6. Anderson-Darling test (AD test)
7. Jarque-Bera test (JB test) 
8. D’Agostino–Pearson Omnibus test (DP test)

Hypothesis testing for Normality assumption(whether the observed sample comes from a population with a normal distribution)

**H0**: Observed sample comes from a population with a normal distribution (OR Non-normal distribution comes from the normal distribution family) (OR Random sample of n independent observations come from a population with a normal $$N(\mu,{\sigma}^2) $$) )
**H1**: Observed sample does not come from a population with a normal distribution (or Non-normal distribution does not come from the normal distribution family.) (OR Random sample of n independent observations does not come from a population with a normal $$N(\mu,{\sigma}^2) $$))

Criteria to do comparison among the 8 normality tests:
1. They all should have the same probability of rejecting the Null Hypothesis when the distribution is truly normal(Same Type-I error rate(significance level: $$\alpha$$ ). Alpha=0.05 is considered for all simulation results.

### 2) Introduction of each test
    ## Touch on the theory, maybe not as in-depth as the paper however


### 3) Introduce the types of distributions and how we generate the random variates

Sample sizes: 10, 15, 20, 25, 30, 40, 50, 100, 200, 300, 400, 500,1 1000, 1500, 2000

## Random variates genearetd from Standard Normal Distributions
1. 50,000 simulated samples for particular sample size are generated using rnorm function with mean=0 and standard deviation=1; and then the Test Statistic values are obtained from them.
2. For a particular sample size, the 50,000 generated test statistics are sorted to generate an empirical distribution
3. quantile function is used to get the sample quantile from the generated empirical distribution for the mentioned probability. That value of sample quantile is used as the Critical value. 
4. Left-tailed test: **SW test** and Critical values are the $$100(\alpha)$$th percentile of the empirical distribution
5. For Right-tailed tests: **AD, LL, CVM, DP,JB and CSQ tests** : and  Two-tailed test: **KS test**: , Critical values are the $$100(1-\alpha)$$th percentiles of the empirical distribution
6. For **CSQ test**, we used different approach than paper to compute the number of bins. We used the R function nclass.scott(x) to compute it. 
7. For **DP Omnibus test**, we have done the modification in original source code, so it can consider the sample size less than 20 as well.

```{r}
# Edited from dagoTest(x) in fBasics library. 
omnibus.test <- function(x){
  # Internal Function for D'Agostino Normality Test:
  
  # FUNCTION:
  if (exists("complete.cases")) {
    test = complete.cases(x)
  } else {
    test = !is.na(x)
  }
  x = x[test]
  n = length(x)
  meanX = mean(x)
  s =  sqrt(mean((x-meanX)**2))
  a3 = mean((x-meanX)**3)/s**3
  a4 = mean((x-meanX)**4)/s**4
  SD3 = sqrt(6*(n-2)/((n+1)*(n+3)))
  SD4 = sqrt(24*(n-2)*(n-3)*n/((n+1)**2*(n+3)*(n+5)))
  U3 = a3/SD3
  U4 = (a4-3+6/(n+1))/SD4
  b  = (3*(n**2+27*n-70)*(n+1)*(n+3))/((n-2)*(n+5)*(n+7)*(n+9))
  W2 = sqrt(2*(b-1))-1
  delta = 1/sqrt(log(sqrt(W2)))
  a = sqrt(2/(W2-1))
  Z3 = delta*log((U3/a)+sqrt((U3/a)**2+1))
  B = (6*(n*n-5*n+2)/((n+7)*(n+9)))*sqrt((6*(n+3)*(n+5))/(n*(n-2)*(n-3)))
  A = 6+(8/B)*((2/B)+sqrt(1+4/(B**2)))
  jm = sqrt(2/(9*A))
  pos = ((1-2/A)/(1+U4*sqrt(2/(A-4))))**(1/3)
  Z4 = (1-2/(9*A)-pos)/jm
  omni = Z3**2+Z4**2
  
  # Result:
  omni
}
```


## Random Variates generated from alternative(non-normal) distributions
1. 10,000 simulated samples for particular sample size were generated from a given non-normal distributions. We have used inbuilt R functions for some distributions and created the home-made functions for some distributions. Then the Test Statistic values were obtained from them.
2. For a particular sample size, the 10,000 generated test statistics were sorted to generate an empirical distribution
3. Steps 3-7 are similar with the steps 3-7 mentioned for generating random variates from standard normal distributions.  
9. The power of the normality test for the 10,000 simulated samples for particular sample size is the proportion of samples which the test rejected the null hypothesis of normality.

### Type of the distributions:

1. **Uniform- U(0,1)**: R function `runif` is used to generate the random variates from uniform distribution.  

2. **Generalised Lamda Distribution(GLD(lambda1, lambda2, lambda3, lambda4))**: R function `gld.moments` is used to generate the random variates for this  distribution for given paramater values.

lambda 1 - location parameter, lambda 2 - scale parameter, 
lambda 3 - first shape parameter, lambda 4 - second shape

3. **Tukey(lambda1, lambda2, lambda3, lambda4)**: This is a type of generalized lamda distribution. So, R function `gld.moments` is used to generate the random variates.
 
4. **Trunc(a,b)**: R function `rtruncnorm` is used to generate the random deviates for this distribution.

5. **Scale Contaminated Normal: ScConN(p,b):** We have created below function to generate the random variates from this distribution.

```{r}
rScConN <- function(n,p,b){
  k <- runif(n)
  k <- ifelse(k <= p, 1, 0)
  ScConNdist <- k*rnorm(n, mean = 0, sd=b) + (1-k)*rnorm(n)
  ScConNdist
}

```


6. **t(15)**: R function `rt` is used to generate the random deviates from this distribution. 

7. **Logistic**: R function `rlogis` is used to generate random deviates from this distribution.
 
8. **Laplace**: R function `rlaplace` is used to generate random deviates from this distribution.

9. **Chi()**: R function `rchisq` is used to generate random deviates from this distribution.

10. **Beta**: R function `rbeta` is used to generate random deviates from this distribution.

11. **Weibull**: R function `rweibull` is used to generate random deviates from this distribution.

12. **Lognormal**: We have created below function to generate the random variates from this distribution.

```{r}
rlog <- function(n){
  x <- rnorm(n,0,1)
  dist <- exp(x)
}
```

13. **Location Contaminated Normal**: We have created below function to generate the random variates from this distribution.

```{r}
rLoConN <- function(n,p,a){
  k <- runif(n)
  k <- ifelse(k <= p, 1, 0)
  LoConNdist <- k*rnorm(n, mean = a, sd=1) + (1-k)*rnorm(n)
  LoConNdist
}

```





### Symmetric Short-tailed Distributions
# Used in Table-2:
# 1. Uniform: U(0,1): 
# 2. Tukey(0,1,1.25,1.25): 
# 3. Trunc(−2,2):

# Used in Figure-1:
# 1. GLD(0,1,0.75,0.75)
# 2. GLD(0,1,0.5,0.5)
# 3. GLD(0,1,0.25,0.25)


### Symmetric long-tailed distributions:
# Used in figure-2:
# 1. GLD(0,1,−0.10,−0.10)
# 2. GLD(0,1,−0.15,−0.15)
# 3. Scale Contaminated Normal: ScConN(0.05,3)

# Used in Table-3:
# 1. t(15)
# 2. Logistic
# 3. Laplace


### Asymmetric distributions:

# Used in Figure-3:
# 1. CSQ(4)
# 2. Beta(2,1)

# Used in Table-4:
# 1. Weibull(3,1)
# 2. Lognormal
# 3. Location Contaminated Normal: LoConN(0.2,3) 


### 4) Talk about the power of each test and how it is defined 

## Section-2: Results
  ## Grabbing critical values
  ## Writing the code for the tests
    ## Specify difficulties with the tests and any changes made.
  ## Introduce by order in the paper (the table/figures) and then comment on        the difficulties associated with each test and distribution. 
      ## Make a comment on anything that did not match.
  ## Summarize the results of the paper
  
## Section-3: Summary
  ## Talk about our own insights, whether we agree with the paper's conclusion,   and the highlights of what we learned while trying to replicate the results o   of the paper. 
## Section-4: Future Work
  ## Discuss how this could apply to future work, both in industry and              academia. 

## References

Research paper:
Yap, Bee Wah, and Chiaw Hock Sim. "Comparisons of various types of normality tests." Journal of Statistical Computation and Simulation 81.12 (2011): 2141-2155.

Book:
Rizzo, Maria L. Statistical computing with R. CRC Press, 2019.

```{r}
citation(package = "stats")
citation(package = "fBasics")
citation(package = "normtest")
citation(package = "lawstat")
citation(package = "gld")
citation(package = "VGAM")
citation(package = "truncnorm")
citation(package="grDevices")
```


## Appendix

